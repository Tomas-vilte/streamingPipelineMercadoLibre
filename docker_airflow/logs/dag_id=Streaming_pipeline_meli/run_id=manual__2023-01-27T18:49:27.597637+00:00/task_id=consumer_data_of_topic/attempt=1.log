[2023-01-27T18:49:28.985+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Streaming_pipeline_meli.consumer_data_of_topic manual__2023-01-27T18:49:27.597637+00:00 [queued]>
[2023-01-27T18:49:29.008+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Streaming_pipeline_meli.consumer_data_of_topic manual__2023-01-27T18:49:27.597637+00:00 [queued]>
[2023-01-27T18:49:29.008+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2023-01-27T18:49:29.008+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 6
[2023-01-27T18:49:29.009+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2023-01-27T18:49:29.035+0000] {taskinstance.py:1304} INFO - Executing <Task(SparkSubmitOperator): consumer_data_of_topic> on 2023-01-27 18:49:27.597637+00:00
[2023-01-27T18:49:29.041+0000] {standard_task_runner.py:55} INFO - Started process 11852 to run task
[2023-01-27T18:49:29.046+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Streaming_pipeline_meli', 'consumer_data_of_topic', 'manual__2023-01-27T18:49:27.597637+00:00', '--job-id', '1141', '--raw', '--subdir', 'DAGS_FOLDER/producer_dag.py', '--cfg-path', '/tmp/tmpxk15pppw']
[2023-01-27T18:49:29.047+0000] {standard_task_runner.py:83} INFO - Job 1141: Subtask consumer_data_of_topic
[2023-01-27T18:49:29.135+0000] {task_command.py:389} INFO - Running <TaskInstance: Streaming_pipeline_meli.consumer_data_of_topic manual__2023-01-27T18:49:27.597637+00:00 [running]> on host 502660defd2e
[2023-01-27T18:49:29.248+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=Streaming_pipeline_meli
AIRFLOW_CTX_TASK_ID=consumer_data_of_topic
AIRFLOW_CTX_EXECUTION_DATE=2023-01-27T18:49:27.597637+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-01-27T18:49:27.597637+00:00
[2023-01-27T18:49:29.262+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2023-01-27T18:49:29.264+0000] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master spark://tomi-H310:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.3,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 --name arrow-spark --queue root.default /opt/***/dags/consumerSpark.py
[2023-01-27T18:49:29.385+0000] {spark_submit.py:495} INFO - /home/***/.local/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2023-01-27T18:49:30.974+0000] {spark_submit.py:495} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.7/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2023-01-27T18:49:31.030+0000] {spark_submit.py:495} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2023-01-27T18:49:31.030+0000] {spark_submit.py:495} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2023-01-27T18:49:31.034+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2023-01-27T18:49:31.034+0000] {spark_submit.py:495} INFO - org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency
[2023-01-27T18:49:31.035+0000] {spark_submit.py:495} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-4d2d9909-0812-4c58-aa79-973efeab73fc;1.0
[2023-01-27T18:49:31.035+0000] {spark_submit.py:495} INFO - confs: [default]
[2023-01-27T18:49:31.186+0000] {spark_submit.py:495} INFO - found org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.3 in central
[2023-01-27T18:49:31.243+0000] {spark_submit.py:495} INFO - found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.3 in central
[2023-01-27T18:49:31.271+0000] {spark_submit.py:495} INFO - found org.apache.kafka#kafka-clients;2.6.0 in central
[2023-01-27T18:49:31.296+0000] {spark_submit.py:495} INFO - found com.github.luben#zstd-jni;1.4.8-1 in central
[2023-01-27T18:49:31.314+0000] {spark_submit.py:495} INFO - found org.lz4#lz4-java;1.7.1 in central
[2023-01-27T18:49:31.329+0000] {spark_submit.py:495} INFO - found org.xerial.snappy#snappy-java;1.1.8.2 in central
[2023-01-27T18:49:31.344+0000] {spark_submit.py:495} INFO - found org.slf4j#slf4j-api;1.7.30 in central
[2023-01-27T18:49:31.358+0000] {spark_submit.py:495} INFO - found org.spark-project.spark#unused;1.0.0 in central
[2023-01-27T18:49:31.372+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-pool2;2.6.2 in central
[2023-01-27T18:49:31.383+0000] {spark_submit.py:495} INFO - found org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central
[2023-01-27T18:49:31.392+0000] {spark_submit.py:495} INFO - found org.mongodb#mongodb-driver-sync;4.0.5 in central
[2023-01-27T18:49:31.409+0000] {spark_submit.py:495} INFO - found org.mongodb#bson;4.0.5 in central
[2023-01-27T18:49:31.423+0000] {spark_submit.py:495} INFO - found org.mongodb#mongodb-driver-core;4.0.5 in central
[2023-01-27T18:49:31.477+0000] {spark_submit.py:495} INFO - :: resolution report :: resolve 425ms :: artifacts dl 17ms
[2023-01-27T18:49:31.478+0000] {spark_submit.py:495} INFO - :: modules in use:
[2023-01-27T18:49:31.478+0000] {spark_submit.py:495} INFO - com.github.luben#zstd-jni;1.4.8-1 from central in [default]
[2023-01-27T18:49:31.478+0000] {spark_submit.py:495} INFO - org.apache.commons#commons-pool2;2.6.2 from central in [default]
[2023-01-27T18:49:31.479+0000] {spark_submit.py:495} INFO - org.apache.kafka#kafka-clients;2.6.0 from central in [default]
[2023-01-27T18:49:31.479+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.3 from central in [default]
[2023-01-27T18:49:31.479+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.3 from central in [default]
[2023-01-27T18:49:31.479+0000] {spark_submit.py:495} INFO - org.lz4#lz4-java;1.7.1 from central in [default]
[2023-01-27T18:49:31.479+0000] {spark_submit.py:495} INFO - org.mongodb#bson;4.0.5 from central in [default]
[2023-01-27T18:49:31.480+0000] {spark_submit.py:495} INFO - org.mongodb#mongodb-driver-core;4.0.5 from central in [default]
[2023-01-27T18:49:31.480+0000] {spark_submit.py:495} INFO - org.mongodb#mongodb-driver-sync;4.0.5 from central in [default]
[2023-01-27T18:49:31.480+0000] {spark_submit.py:495} INFO - org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]
[2023-01-27T18:49:31.482+0000] {spark_submit.py:495} INFO - org.slf4j#slf4j-api;1.7.30 from central in [default]
[2023-01-27T18:49:31.483+0000] {spark_submit.py:495} INFO - org.spark-project.spark#unused;1.0.0 from central in [default]
[2023-01-27T18:49:31.483+0000] {spark_submit.py:495} INFO - org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
[2023-01-27T18:49:31.483+0000] {spark_submit.py:495} INFO - ---------------------------------------------------------------------
[2023-01-27T18:49:31.483+0000] {spark_submit.py:495} INFO - |                  |            modules            ||   artifacts   |
[2023-01-27T18:49:31.484+0000] {spark_submit.py:495} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2023-01-27T18:49:31.484+0000] {spark_submit.py:495} INFO - ---------------------------------------------------------------------
[2023-01-27T18:49:31.485+0000] {spark_submit.py:495} INFO - |      default     |   13  |   0   |   0   |   0   ||   13  |   0   |
[2023-01-27T18:49:31.485+0000] {spark_submit.py:495} INFO - ---------------------------------------------------------------------
[2023-01-27T18:49:31.504+0000] {spark_submit.py:495} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-4d2d9909-0812-4c58-aa79-973efeab73fc
[2023-01-27T18:49:31.505+0000] {spark_submit.py:495} INFO - confs: [default]
[2023-01-27T18:49:31.518+0000] {spark_submit.py:495} INFO - 0 artifacts copied, 13 already retrieved (0kB/12ms)
[2023-01-27T18:49:31.812+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-01-27T18:49:33.273+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO SparkContext: Running Spark version 3.3.1
[2023-01-27T18:49:33.305+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO ResourceUtils: ==============================================================
[2023-01-27T18:49:33.306+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-01-27T18:49:33.307+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO ResourceUtils: ==============================================================
[2023-01-27T18:49:33.307+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO SparkContext: Submitted application: arrow-spark
[2023-01-27T18:49:33.381+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-01-27T18:49:33.407+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO ResourceProfile: Limiting resource is cpu
[2023-01-27T18:49:33.408+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-01-27T18:49:33.453+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO SecurityManager: Changing view acls to: default
[2023-01-27T18:49:33.454+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO SecurityManager: Changing modify acls to: default
[2023-01-27T18:49:33.457+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO SecurityManager: Changing view acls groups to:
[2023-01-27T18:49:33.458+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO SecurityManager: Changing modify acls groups to:
[2023-01-27T18:49:33.459+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(default); groups with view permissions: Set(); users  with modify permissions: Set(default); groups with modify permissions: Set()
[2023-01-27T18:49:34.010+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Successfully started service 'sparkDriver' on port 36465.
[2023-01-27T18:49:34.128+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkEnv: Registering MapOutputTracker
[2023-01-27T18:49:34.183+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkEnv: Registering BlockManagerMaster
[2023-01-27T18:49:34.209+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-01-27T18:49:34.210+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-01-27T18:49:34.226+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-01-27T18:49:34.262+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0110409a-b72f-4c12-9f11-f569b44d9a99
[2023-01-27T18:49:34.280+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-01-27T18:49:34.296+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-01-27T18:49:34.446+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2023-01-27T18:49:34.453+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2023-01-27T18:49:34.478+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar at spark://502660defd2e:36465/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:34.478+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at spark://502660defd2e:36465/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar at spark://502660defd2e:36465/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at spark://502660defd2e:36465/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://502660defd2e:36465/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://502660defd2e:36465/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at spark://502660defd2e:36465/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://502660defd2e:36465/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at spark://502660defd2e:36465/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1674845373261
[2023-01-27T18:49:34.479+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://502660defd2e:36465/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1674845373261
[2023-01-27T18:49:34.480+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at spark://502660defd2e:36465/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.480+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar at spark://502660defd2e:36465/jars/org.mongodb_bson-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.480+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at spark://502660defd2e:36465/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.481+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar at file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:34.482+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar
[2023-01-27T18:49:34.492+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.492+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2023-01-27T18:49:34.502+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar at file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:34.503+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar
[2023-01-27T18:49:34.507+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1674845373261
[2023-01-27T18:49:34.507+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.kafka_kafka-clients-2.6.0.jar
[2023-01-27T18:49:34.513+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1674845373261
[2023-01-27T18:49:34.513+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.commons_commons-pool2-2.6.2.jar
[2023-01-27T18:49:34.517+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1674845373261
[2023-01-27T18:49:34.517+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.spark-project.spark_unused-1.0.0.jar
[2023-01-27T18:49:34.520+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.520+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/com.github.luben_zstd-jni-1.4.8-1.jar
[2023-01-27T18:49:34.529+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.529+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.lz4_lz4-java-1.7.1.jar
[2023-01-27T18:49:34.532+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1674845373261
[2023-01-27T18:49:34.533+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.xerial.snappy_snappy-java-1.1.8.2.jar
[2023-01-27T18:49:34.538+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1674845373261
[2023-01-27T18:49:34.538+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.slf4j_slf4j-api-1.7.30.jar
[2023-01-27T18:49:34.541+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.542+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2023-01-27T18:49:34.545+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar at file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.545+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_bson-4.0.5.jar
[2023-01-27T18:49:34.549+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.549+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-core-4.0.5.jar
[2023-01-27T18:49:34.601+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Starting executor ID driver on host 502660defd2e
[2023-01-27T18:49:34.615+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-01-27T18:49:34.617+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:34.630+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar
[2023-01-27T18:49:34.634+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.637+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2023-01-27T18:49:34.642+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1674845373261
[2023-01-27T18:49:34.647+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.kafka_kafka-clients-2.6.0.jar
[2023-01-27T18:49:34.654+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.655+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_bson-4.0.5.jar
[2023-01-27T18:49:34.658+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.663+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/com.github.luben_zstd-jni-1.4.8-1.jar
[2023-01-27T18:49:34.671+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.672+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.lz4_lz4-java-1.7.1.jar
[2023-01-27T18:49:34.690+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1674845373261
[2023-01-27T18:49:34.691+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.spark-project.spark_unused-1.0.0.jar
[2023-01-27T18:49:34.693+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1674845373261
[2023-01-27T18:49:34.696+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.xerial.snappy_snappy-java-1.1.8.2.jar
[2023-01-27T18:49:34.702+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.709+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-core-4.0.5.jar
[2023-01-27T18:49:34.731+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:34.732+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar
[2023-01-27T18:49:34.754+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.755+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2023-01-27T18:49:34.766+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1674845373261
[2023-01-27T18:49:34.766+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.commons_commons-pool2-2.6.2.jar
[2023-01-27T18:49:34.775+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1674845373261
[2023-01-27T18:49:34.775+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.slf4j_slf4j-api-1.7.30.jar
[2023-01-27T18:49:34.785+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1674845373261
[2023-01-27T18:49:34.817+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO TransportClientFactory: Successfully created connection to 502660defd2e/172.23.0.7:36465 after 24 ms (0 ms spent in bootstraps)
[2023-01-27T18:49:34.823+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp14337777761962722302.tmp
[2023-01-27T18:49:34.854+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp14337777761962722302.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.spark-project.spark_unused-1.0.0.jar
[2023-01-27T18:49:34.866+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.spark-project.spark_unused-1.0.0.jar to class loader
[2023-01-27T18:49:34.866+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.mongodb_bson-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:34.867+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.mongodb_bson-4.0.5.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp13275858306976588778.tmp
[2023-01-27T18:49:34.870+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp13275858306976588778.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_bson-4.0.5.jar
[2023-01-27T18:49:34.873+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_bson-4.0.5.jar to class loader
[2023-01-27T18:49:34.873+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching spark://502660defd2e:36465/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1674845373261
[2023-01-27T18:49:34.874+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Fetching spark://502660defd2e:36465/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp855495044105514587.tmp
[2023-01-27T18:49:34.896+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp855495044105514587.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/com.github.luben_zstd-jni-1.4.8-1.jar
[2023-01-27T18:49:34.980+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/com.github.luben_zstd-jni-1.4.8-1.jar to class loader
[2023-01-27T18:49:34.981+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:34.983+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp5660223832457081990.tmp
[2023-01-27T18:49:34.992+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:34 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp5660223832457081990.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar
[2023-01-27T18:49:35.009+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar to class loader
[2023-01-27T18:49:35.009+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1674845373261
[2023-01-27T18:49:35.010+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp18129663222880768523.tmp
[2023-01-27T18:49:35.030+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp18129663222880768523.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.lz4_lz4-java-1.7.1.jar
[2023-01-27T18:49:35.039+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.lz4_lz4-java-1.7.1.jar to class loader
[2023-01-27T18:49:35.040+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:35.041+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp986382627253753434.tmp
[2023-01-27T18:49:35.046+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp986382627253753434.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2023-01-27T18:49:35.057+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-sync-4.0.5.jar to class loader
[2023-01-27T18:49:35.058+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1674845373261
[2023-01-27T18:49:35.059+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp16924074748896457201.tmp
[2023-01-27T18:49:35.063+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp16924074748896457201.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar
[2023-01-27T18:49:35.075+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar to class loader
[2023-01-27T18:49:35.075+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1674845373261
[2023-01-27T18:49:35.080+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp304415784267796024.tmp
[2023-01-27T18:49:35.085+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp304415784267796024.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.slf4j_slf4j-api-1.7.30.jar
[2023-01-27T18:49:35.099+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.slf4j_slf4j-api-1.7.30.jar to class loader
[2023-01-27T18:49:35.101+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1674845373261
[2023-01-27T18:49:35.102+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp17964349812157082092.tmp
[2023-01-27T18:49:35.196+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp17964349812157082092.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.kafka_kafka-clients-2.6.0.jar
[2023-01-27T18:49:35.202+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.kafka_kafka-clients-2.6.0.jar to class loader
[2023-01-27T18:49:35.202+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1674845373261
[2023-01-27T18:49:35.205+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp12157002588170733147.tmp
[2023-01-27T18:49:35.211+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp12157002588170733147.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2023-01-27T18:49:35.216+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to class loader
[2023-01-27T18:49:35.216+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1674845373261
[2023-01-27T18:49:35.216+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp2589883009378235883.tmp
[2023-01-27T18:49:35.218+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp2589883009378235883.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.commons_commons-pool2-2.6.2.jar
[2023-01-27T18:49:35.226+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.apache.commons_commons-pool2-2.6.2.jar to class loader
[2023-01-27T18:49:35.226+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1674845373261
[2023-01-27T18:49:35.227+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.mongodb_mongodb-driver-core-4.0.5.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp3425546484203542899.tmp
[2023-01-27T18:49:35.234+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp3425546484203542899.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-core-4.0.5.jar
[2023-01-27T18:49:35.238+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.mongodb_mongodb-driver-core-4.0.5.jar to class loader
[2023-01-27T18:49:35.239+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Fetching spark://502660defd2e:36465/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1674845373261
[2023-01-27T18:49:35.241+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Fetching spark://502660defd2e:36465/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp13609699627508802145.tmp
[2023-01-27T18:49:35.247+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/fetchFileTemp13609699627508802145.tmp has been previously copied to /tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.xerial.snappy_snappy-java-1.1.8.2.jar
[2023-01-27T18:49:35.328+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Executor: Adding file:/tmp/spark-a3ecb5f5-6ced-44fc-a933-d45839ecf7b6/userFiles-0b43cd1e-47e2-4b1a-a754-9cb0d1b778ba/org.xerial.snappy_snappy-java-1.1.8.2.jar to class loader
[2023-01-27T18:49:35.350+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33125.
[2023-01-27T18:49:35.350+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO NettyBlockTransferService: Server created on 502660defd2e:33125
[2023-01-27T18:49:35.355+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-01-27T18:49:35.373+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 502660defd2e, 33125, None)
[2023-01-27T18:49:35.381+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO BlockManagerMasterEndpoint: Registering block manager 502660defd2e:33125 with 434.4 MiB RAM, BlockManagerId(driver, 502660defd2e, 33125, None)
[2023-01-27T18:49:35.388+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 502660defd2e, 33125, None)
[2023-01-27T18:49:35.391+0000] {spark_submit.py:495} INFO - 23/01/27 18:49:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 502660defd2e, 33125, None)
[2023-01-27T18:49:38.963+0000] {spark_submit.py:495} INFO - 2023-01-27 18:49:38,963 - py4j.java_gateway - INFO - Callback Server Starting
[2023-01-27T18:49:38.964+0000] {spark_submit.py:495} INFO - 2023-01-27 18:49:38,963 - py4j.java_gateway - INFO - Socket listening on ('127.0.0.1', 35351)
[2023-01-27T18:50:59.680+0000] {spark_submit.py:495} INFO - 2023-01-27 18:50:59,677 - py4j.clientserver - INFO - Python Server ready to receive messages
[2023-01-27T18:50:59.681+0000] {spark_submit.py:495} INFO - 2023-01-27 18:50:59,677 - py4j.clientserver - INFO - Received command c on object id p0
[2023-01-27T18:51:00.773+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:51:00.774+0000] {spark_submit.py:495} INFO - Batch: 0
[2023-01-27T18:51:00.774+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:51:00.894+0000] {spark_submit.py:495} INFO - +---+-------------+-----+-------------+----------+----------------+------------+-----------------+--------------+-------------+
[2023-01-27T18:51:00.894+0000] {spark_submit.py:495} INFO - | id|nameOfProduct|price|ProductStatus|SellerName|RegistrationDate|QuantitySold|QuantityAvailable|Free shipping?|Store ratings|
[2023-01-27T18:51:00.894+0000] {spark_submit.py:495} INFO - +---+-------------+-----+-------------+----------+----------------+------------+-----------------+--------------+-------------+
[2023-01-27T18:51:00.894+0000] {spark_submit.py:495} INFO - +---+-------------+-----+-------------+----------+----------------+------------+-----------------+--------------+-------------+
[2023-01-27T18:51:00.894+0000] {spark_submit.py:495} INFO - 
[2023-01-27T18:51:01.600+0000] {spark_submit.py:495} INFO - 2023-01-27 18:51:01,595 - py4j.clientserver - INFO - Received command c on object id p0
[2023-01-27T18:51:05.851+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:51:05.852+0000] {spark_submit.py:495} INFO - Batch: 1
[2023-01-27T18:51:05.852+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:51:05.957+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |           id|       nameOfProduct|   price|ProductStatus|          SellerName|   RegistrationDate|QuantitySold|QuantityAvailable|      Free shipping?|Store ratings|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |MLA1221192372|Disco Duro Extern...| 25999.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|         250|              100|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |MLA1157512489|Placa De Video Nv...|124999.0|          new|      PCREGISTRADAOK|2020-11-02 13:17:33|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |MLA1283547951|Procesador Amd Ry...| 94000.0|          new|    ARBOTECH ELECTRO|2021-03-02 21:46:27|           5|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |MLA1163238194|Placa De Video Am...| 33999.0|          new|       MICYBERCOMPRA|2011-09-13 13:15:53|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |MLA1148481665|Microprocesador P...| 58899.0|          new|            MALL WEB|2016-05-26 20:28:35|         150|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |MLA1318244331|Disco Solido Ssd ...| 28799.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|           5|              150|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - | MLA923637669|Placa De Video Ge...| 28699.0|          new|         INDIGOTRADE|2018-01-05 19:21:16|         500|               50|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.958+0000] {spark_submit.py:495} INFO - |MLA1106592620|Disco Slido Inte...| 13125.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|You have to pay t...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - | MLA882277177|Capturadora Video...|  2699.0|          new|         BSK-IMPORTS|2019-12-30 23:07:04|         500|               50|You have to pay t...|          3.0|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - |MLA1183925519|Placa De Video Nv...|299999.0|          new|ESTUDIOSMPSRLESTU...|2020-11-29 18:36:32|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - | MLA902808321|Procesador Gamer ...| 23699.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - |MLA1119996182|Disco Slido Inte...| 25499.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - |MLA1160204806|Memoria Ram Fury ...| 15399.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|         500|               50|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - | MLA844489972|Disco Duro Intern...| 11599.0|          new|           DALECLCK|2015-03-16 12:07:23|        5000|              500|You have to pay t...|          5.0|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - | MLA620399442|Turbina Cooler Fa...| 2896.32|          new|          LOCALNUEVE|2011-03-10 23:40:59|        5000|              250|You have to pay t...|          3.0|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - |MLA1142513995|Procesador Intel ...| 23500.0|          new|          REFILLKIT1|2018-07-16 12:20:57|           0|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - |MLA1228990119|Memoria Ram Fury ...| 23000.0|          new|MARSTECHSRLMARSTE...|2020-08-05 14:27:59|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - |MLA1301642528|Placa De Video Nv...|124999.0|          new|     ITS-COMPUTACION|2012-10-18 20:37:49|           5|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.959+0000] {spark_submit.py:495} INFO - |MLA1191581442|Disco Slido Inte...| 26949.0|          new|          STARS SHOP|2011-12-28 14:25:32|         150|                1|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.960+0000] {spark_submit.py:495} INFO - |MLA1302136118|Disco Duro Intern...| 18271.0|          new|DIAMONDSYSTEMSANJ...|2016-04-08 17:21:06|         150|               50|Your shipment arr...|          4.5|
[2023-01-27T18:51:05.960+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:51:05.960+0000] {spark_submit.py:495} INFO - only showing top 20 rows
[2023-01-27T18:51:05.960+0000] {spark_submit.py:495} INFO - 
[2023-01-27T18:55:03.990+0000] {spark_submit.py:495} INFO - 2023-01-27 18:55:03,989 - py4j.clientserver - INFO - Received command c on object id p0
[2023-01-27T18:55:05.351+0000] {spark_submit.py:495} INFO - 2023-01-27 18:55:05,351 - py4j.clientserver - INFO - Received command c on object id p0
[2023-01-27T18:55:06.445+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:55:06.445+0000] {spark_submit.py:495} INFO - Batch: 2
[2023-01-27T18:55:06.445+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:55:06.486+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - |           id|       nameOfProduct|   price|ProductStatus|          SellerName|   RegistrationDate|QuantitySold|QuantityAvailable|      Free shipping?|Store ratings|
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - |MLA1221192372|Disco Duro Extern...| 25999.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|         250|              100|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - |MLA1157512489|Placa De Video Nv...|124999.0|          new|      PCREGISTRADAOK|2020-11-02 13:17:33|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - |MLA1283547951|Procesador Amd Ry...| 94000.0|          new|    ARBOTECH ELECTRO|2021-03-02 21:46:27|           5|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - |MLA1163238194|Placa De Video Am...| 33999.0|          new|       MICYBERCOMPRA|2011-09-13 13:15:53|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - |MLA1148481665|Microprocesador P...| 58899.0|          new|            MALL WEB|2016-05-26 20:28:35|         150|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.487+0000] {spark_submit.py:495} INFO - |MLA1318244331|Disco Solido Ssd ...| 28799.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|           5|              150|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.488+0000] {spark_submit.py:495} INFO - | MLA923637669|Placa De Video Ge...| 28699.0|          new|         INDIGOTRADE|2018-01-05 19:21:16|         500|               50|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.488+0000] {spark_submit.py:495} INFO - |MLA1106592620|Disco Slido Inte...| 13125.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|You have to pay t...|          4.5|
[2023-01-27T18:55:06.488+0000] {spark_submit.py:495} INFO - | MLA882277177|Capturadora Video...|  2699.0|          new|         BSK-IMPORTS|2019-12-30 23:07:04|         500|               50|You have to pay t...|          3.0|
[2023-01-27T18:55:06.488+0000] {spark_submit.py:495} INFO - |MLA1183925519|Placa De Video Nv...|299999.0|          new|ESTUDIOSMPSRLESTU...|2020-11-29 18:36:32|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.489+0000] {spark_submit.py:495} INFO - | MLA902808321|Procesador Gamer ...| 23699.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.489+0000] {spark_submit.py:495} INFO - |MLA1119996182|Disco Slido Inte...| 25499.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.489+0000] {spark_submit.py:495} INFO - |MLA1160204806|Memoria Ram Fury ...| 15399.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|         500|               50|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.489+0000] {spark_submit.py:495} INFO - | MLA844489972|Disco Duro Intern...| 11599.0|          new|           DALECLCK|2015-03-16 12:07:23|        5000|              500|You have to pay t...|          5.0|
[2023-01-27T18:55:06.489+0000] {spark_submit.py:495} INFO - | MLA620399442|Turbina Cooler Fa...| 2896.32|          new|          LOCALNUEVE|2011-03-10 23:40:59|        5000|              250|You have to pay t...|          3.0|
[2023-01-27T18:55:06.489+0000] {spark_submit.py:495} INFO - |MLA1142513995|Procesador Intel ...| 23500.0|          new|          REFILLKIT1|2018-07-16 12:20:57|           0|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.489+0000] {spark_submit.py:495} INFO - |MLA1228990119|Memoria Ram Fury ...| 23000.0|          new|MARSTECHSRLMARSTE...|2020-08-05 14:27:59|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.490+0000] {spark_submit.py:495} INFO - |MLA1301642528|Placa De Video Nv...|124999.0|          new|     ITS-COMPUTACION|2012-10-18 20:37:49|           5|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.491+0000] {spark_submit.py:495} INFO - |MLA1191581442|Disco Slido Inte...| 26949.0|          new|          STARS SHOP|2011-12-28 14:25:32|         150|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.491+0000] {spark_submit.py:495} INFO - |MLA1302136118|Disco Duro Intern...| 18271.0|          new|DIAMONDSYSTEMSANJ...|2016-04-08 17:21:06|         150|               50|Your shipment arr...|          4.5|
[2023-01-27T18:55:06.491+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:55:06.491+0000] {spark_submit.py:495} INFO - only showing top 20 rows
[2023-01-27T18:55:06.493+0000] {spark_submit.py:495} INFO - 
[2023-01-27T18:55:16.594+0000] {spark_submit.py:495} INFO - 2023-01-27 18:55:16,594 - py4j.clientserver - INFO - Received command c on object id p0
[2023-01-27T18:55:17.966+0000] {spark_submit.py:495} INFO - 2023-01-27 18:55:17,965 - py4j.clientserver - INFO - Received command c on object id p0
[2023-01-27T18:55:20.815+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:55:20.815+0000] {spark_submit.py:495} INFO - Batch: 3
[2023-01-27T18:55:20.815+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-01-27T18:55:20.868+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:55:20.869+0000] {spark_submit.py:495} INFO - |           id|       nameOfProduct|   price|ProductStatus|          SellerName|   RegistrationDate|QuantitySold|QuantityAvailable|      Free shipping?|Store ratings|
[2023-01-27T18:55:20.869+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:55:20.869+0000] {spark_submit.py:495} INFO - |MLA1221192372|Disco Duro Extern...| 25999.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|         250|              100|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.869+0000] {spark_submit.py:495} INFO - |MLA1157512489|Placa De Video Nv...|124999.0|          new|      PCREGISTRADAOK|2020-11-02 13:17:33|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.869+0000] {spark_submit.py:495} INFO - |MLA1283547951|Procesador Amd Ry...| 94000.0|          new|    ARBOTECH ELECTRO|2021-03-02 21:46:27|           5|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - |MLA1163238194|Placa De Video Am...| 33999.0|          new|       MICYBERCOMPRA|2011-09-13 13:15:53|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - |MLA1148481665|Microprocesador P...| 58899.0|          new|            MALL WEB|2016-05-26 20:28:35|         150|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - |MLA1318244331|Disco Solido Ssd ...| 28799.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|           5|              150|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - | MLA923637669|Placa De Video Ge...| 28699.0|          new|         INDIGOTRADE|2018-01-05 19:21:16|         500|               50|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - |MLA1106592620|Disco Slido Inte...| 13125.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|You have to pay t...|          4.5|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - | MLA882277177|Capturadora Video...|  2699.0|          new|         BSK-IMPORTS|2019-12-30 23:07:04|         500|               50|You have to pay t...|          3.0|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - |MLA1183925519|Placa De Video Nv...|299999.0|          new|ESTUDIOSMPSRLESTU...|2020-11-29 18:36:32|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.870+0000] {spark_submit.py:495} INFO - | MLA902808321|Procesador Gamer ...| 23699.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.871+0000] {spark_submit.py:495} INFO - |MLA1119996182|Disco Slido Inte...| 25499.0|          new|            MALL WEB|2016-05-26 20:28:35|         500|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.871+0000] {spark_submit.py:495} INFO - |MLA1160204806|Memoria Ram Fury ...| 15399.0|          new|    OVERHARD DIGITAL|2015-01-08 12:19:41|         500|               50|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.871+0000] {spark_submit.py:495} INFO - | MLA844489972|Disco Duro Intern...| 11599.0|          new|           DALECLCK|2015-03-16 12:07:23|        5000|              500|You have to pay t...|          5.0|
[2023-01-27T18:55:20.871+0000] {spark_submit.py:495} INFO - | MLA620399442|Turbina Cooler Fa...| 2896.32|          new|          LOCALNUEVE|2011-03-10 23:40:59|        5000|              250|You have to pay t...|          3.0|
[2023-01-27T18:55:20.871+0000] {spark_submit.py:495} INFO - |MLA1142513995|Procesador Intel ...| 23500.0|          new|          REFILLKIT1|2018-07-16 12:20:57|           0|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.871+0000] {spark_submit.py:495} INFO - |MLA1228990119|Memoria Ram Fury ...| 23000.0|          new|MARSTECHSRLMARSTE...|2020-08-05 14:27:59|          50|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.872+0000] {spark_submit.py:495} INFO - |MLA1301642528|Placa De Video Nv...|124999.0|          new|     ITS-COMPUTACION|2012-10-18 20:37:49|           5|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.872+0000] {spark_submit.py:495} INFO - |MLA1191581442|Disco Slido Inte...| 26949.0|          new|          STARS SHOP|2011-12-28 14:25:32|         150|                1|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.872+0000] {spark_submit.py:495} INFO - |MLA1302136118|Disco Duro Intern...| 18271.0|          new|DIAMONDSYSTEMSANJ...|2016-04-08 17:21:06|         150|               50|Your shipment arr...|          4.5|
[2023-01-27T18:55:20.872+0000] {spark_submit.py:495} INFO - +-------------+--------------------+--------+-------------+--------------------+-------------------+------------+-----------------+--------------------+-------------+
[2023-01-27T18:55:20.872+0000] {spark_submit.py:495} INFO - only showing top 20 rows
[2023-01-27T18:55:20.872+0000] {spark_submit.py:495} INFO - 
[2023-01-27T23:06:02.907+0000] {local_task_job.py:224} WARNING - State of this instance has been externally set to up_for_retry. Terminating instance.
[2023-01-27T23:06:02.908+0000] {process_utils.py:133} INFO - Sending Signals.SIGTERM to group 11852. PIDs of all processes in the group: [11853, 11915, 11852]
[2023-01-27T23:06:02.909+0000] {process_utils.py:84} INFO - Sending the signal Signals.SIGTERM to group 11852
[2023-01-27T23:06:02.909+0000] {taskinstance.py:1483} ERROR - Received SIGTERM. Terminating subprocesses.
[2023-01-27T23:06:02.910+0000] {spark_submit.py:620} INFO - Sending kill signal to spark-submit
[2023-01-27T23:06:02.954+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 157, in execute
    self._hook.submit(self._application)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 414, in submit
    self._process_spark_submit_log(iter(self._submit_sp.stdout))  # type: ignore
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/apache/spark/hooks/spark_submit.py", line 463, in _process_spark_submit_log
    for line in itr:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1485, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2023-01-27T23:06:02.961+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=Streaming_pipeline_meli, task_id=consumer_data_of_topic, execution_date=20230127T184927, start_date=20230127T184928, end_date=20230127T230602
[2023-01-27T23:06:02.981+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 1141 for task consumer_data_of_topic (Task received SIGTERM signal; 11852)
[2023-01-27T23:06:03.024+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=11915, status='terminated', started='18:49:31') (11915) terminated with exit code None
[2023-01-27T23:06:03.024+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=11853, status='terminated', started='18:49:28') (11853) terminated with exit code None
[2023-01-27T23:06:03.024+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=11852, status='terminated', exitcode=1, started='18:49:28') (11852) terminated with exit code 1
