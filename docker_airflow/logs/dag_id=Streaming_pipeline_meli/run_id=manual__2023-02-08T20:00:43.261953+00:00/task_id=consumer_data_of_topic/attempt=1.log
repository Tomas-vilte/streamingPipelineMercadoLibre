[2023-02-08T20:00:45.088+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Streaming_pipeline_meli.consumer_data_of_topic manual__2023-02-08T20:00:43.261953+00:00 [queued]>
[2023-02-08T20:00:45.098+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: Streaming_pipeline_meli.consumer_data_of_topic manual__2023-02-08T20:00:43.261953+00:00 [queued]>
[2023-02-08T20:00:45.098+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2023-02-08T20:00:45.098+0000] {taskinstance.py:1284} INFO - Starting attempt 1 of 6
[2023-02-08T20:00:45.098+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2023-02-08T20:00:45.115+0000] {taskinstance.py:1304} INFO - Executing <Task(SparkSubmitOperator): consumer_data_of_topic> on 2023-02-08 20:00:43.261953+00:00
[2023-02-08T20:00:45.118+0000] {standard_task_runner.py:55} INFO - Started process 1129 to run task
[2023-02-08T20:00:45.122+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'Streaming_pipeline_meli', 'consumer_data_of_topic', 'manual__2023-02-08T20:00:43.261953+00:00', '--job-id', '1377', '--raw', '--subdir', 'DAGS_FOLDER/streamPipeline.py', '--cfg-path', '/tmp/tmpwhgpjyia']
[2023-02-08T20:00:45.122+0000] {standard_task_runner.py:83} INFO - Job 1377: Subtask consumer_data_of_topic
[2023-02-08T20:00:45.181+0000] {task_command.py:389} INFO - Running <TaskInstance: Streaming_pipeline_meli.consumer_data_of_topic manual__2023-02-08T20:00:43.261953+00:00 [running]> on host b55acaa82944
[2023-02-08T20:00:45.245+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=Streaming_pipeline_meli
AIRFLOW_CTX_TASK_ID=consumer_data_of_topic
AIRFLOW_CTX_EXECUTION_DATE=2023-02-08T20:00:43.261953+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-02-08T20:00:43.261953+00:00
[2023-02-08T20:00:45.253+0000] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2023-02-08T20:00:45.254+0000] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master spark://tomi-H310:7077 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.3,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 --name arrow-spark --queue root.default /opt/***/dags/consumerSpark.py
[2023-02-08T20:00:45.356+0000] {spark_submit.py:495} INFO - /home/***/.local/lib/python3.7/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found
[2023-02-08T20:00:47.393+0000] {spark_submit.py:495} INFO - :: loading settings :: url = jar:file:/home/***/.local/lib/python3.7/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
[2023-02-08T20:00:47.464+0000] {spark_submit.py:495} INFO - Ivy Default Cache set to: /home/***/.ivy2/cache
[2023-02-08T20:00:47.464+0000] {spark_submit.py:495} INFO - The jars for the packages stored in: /home/***/.ivy2/jars
[2023-02-08T20:00:47.468+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
[2023-02-08T20:00:47.469+0000] {spark_submit.py:495} INFO - org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency
[2023-02-08T20:00:47.470+0000] {spark_submit.py:495} INFO - :: resolving dependencies :: org.apache.spark#spark-submit-parent-d84e4a54-476c-4b5a-b5b5-9f4815458db2;1.0
[2023-02-08T20:00:47.470+0000] {spark_submit.py:495} INFO - confs: [default]
[2023-02-08T20:00:52.098+0000] {spark_submit.py:495} INFO - found org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.3 in central
[2023-02-08T20:00:52.768+0000] {spark_submit.py:495} INFO - found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.3 in central
[2023-02-08T20:00:53.085+0000] {spark_submit.py:495} INFO - found org.apache.kafka#kafka-clients;2.6.0 in central
[2023-02-08T20:00:53.386+0000] {spark_submit.py:495} INFO - found com.github.luben#zstd-jni;1.4.8-1 in central
[2023-02-08T20:00:53.715+0000] {spark_submit.py:495} INFO - found org.lz4#lz4-java;1.7.1 in central
[2023-02-08T20:00:54.056+0000] {spark_submit.py:495} INFO - found org.xerial.snappy#snappy-java;1.1.8.2 in central
[2023-02-08T20:00:55.628+0000] {spark_submit.py:495} INFO - found org.slf4j#slf4j-api;1.7.30 in central
[2023-02-08T20:00:57.127+0000] {spark_submit.py:495} INFO - found org.spark-project.spark#unused;1.0.0 in central
[2023-02-08T20:00:59.953+0000] {spark_submit.py:495} INFO - found org.apache.commons#commons-pool2;2.6.2 in central
[2023-02-08T20:01:00.279+0000] {spark_submit.py:495} INFO - found org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central
[2023-02-08T20:01:00.601+0000] {spark_submit.py:495} INFO - found org.mongodb#mongodb-driver-sync;4.0.5 in central
[2023-02-08T20:01:00.934+0000] {spark_submit.py:495} INFO - found org.mongodb#bson;4.0.5 in central
[2023-02-08T20:01:01.245+0000] {spark_submit.py:495} INFO - found org.mongodb#mongodb-driver-core;4.0.5 in central
[2023-02-08T20:01:01.433+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.3/spark-sql-kafka-0-10_2.12-3.1.3.jar ...
[2023-02-08T20:01:01.792+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.3!spark-sql-kafka-0-10_2.12.jar (524ms)
[2023-02-08T20:01:01.941+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/3.0.1/mongo-spark-connector_2.12-3.0.1.jar ...
[2023-02-08T20:01:02.229+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.mongodb.spark#mongo-spark-connector_2.12;3.0.1!mongo-spark-connector_2.12.jar (435ms)
[2023-02-08T20:01:02.377+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.1.3/spark-token-provider-kafka-0-10_2.12-3.1.3.jar ...
[2023-02-08T20:01:02.526+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.3!spark-token-provider-kafka-0-10_2.12.jar (294ms)
[2023-02-08T20:01:02.682+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.6.0/kafka-clients-2.6.0.jar ...
[2023-02-08T20:01:03.191+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.kafka#kafka-clients;2.6.0!kafka-clients.jar (663ms)
[2023-02-08T20:01:03.334+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar ...
[2023-02-08T20:01:03.490+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.apache.commons#commons-pool2;2.6.2!commons-pool2.jar (298ms)
[2023-02-08T20:01:03.635+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...
[2023-02-08T20:01:03.781+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (290ms)
[2023-02-08T20:01:03.931+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.8-1/zstd-jni-1.4.8-1.jar ...
[2023-02-08T20:01:04.621+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] com.github.luben#zstd-jni;1.4.8-1!zstd-jni.jar (835ms)
[2023-02-08T20:01:04.768+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar ...
[2023-02-08T20:01:04.962+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.lz4#lz4-java;1.7.1!lz4-java.jar (339ms)
[2023-02-08T20:01:05.111+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar ...
[2023-02-08T20:01:05.424+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.2!snappy-java.jar(bundle) (462ms)
[2023-02-08T20:01:05.568+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar ...
[2023-02-08T20:01:05.711+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.slf4j#slf4j-api;1.7.30!slf4j-api.jar (286ms)
[2023-02-08T20:01:05.858+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.0.5/mongodb-driver-sync-4.0.5.jar ...
[2023-02-08T20:01:06.014+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.mongodb#mongodb-driver-sync;4.0.5!mongodb-driver-sync.jar (301ms)
[2023-02-08T20:01:06.164+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/mongodb/bson/4.0.5/bson-4.0.5.jar ...
[2023-02-08T20:01:06.373+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.mongodb#bson;4.0.5!bson.jar (355ms)
[2023-02-08T20:01:06.520+0000] {spark_submit.py:495} INFO - downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.0.5/mongodb-driver-core-4.0.5.jar ...
[2023-02-08T20:01:06.816+0000] {spark_submit.py:495} INFO - [SUCCESSFUL ] org.mongodb#mongodb-driver-core;4.0.5!mongodb-driver-core.jar (443ms)
[2023-02-08T20:01:06.816+0000] {spark_submit.py:495} INFO - :: resolution report :: resolve 13796ms :: artifacts dl 5550ms
[2023-02-08T20:01:06.816+0000] {spark_submit.py:495} INFO - :: modules in use:
[2023-02-08T20:01:06.816+0000] {spark_submit.py:495} INFO - com.github.luben#zstd-jni;1.4.8-1 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.apache.commons#commons-pool2;2.6.2 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.apache.kafka#kafka-clients;2.6.0 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.3 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.3 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.lz4#lz4-java;1.7.1 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.mongodb#bson;4.0.5 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.mongodb#mongodb-driver-core;4.0.5 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.mongodb#mongodb-driver-sync;4.0.5 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.slf4j#slf4j-api;1.7.30 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.spark-project.spark#unused;1.0.0 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
[2023-02-08T20:01:06.817+0000] {spark_submit.py:495} INFO - ---------------------------------------------------------------------
[2023-02-08T20:01:06.818+0000] {spark_submit.py:495} INFO - |                  |            modules            ||   artifacts   |
[2023-02-08T20:01:06.818+0000] {spark_submit.py:495} INFO - |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
[2023-02-08T20:01:06.818+0000] {spark_submit.py:495} INFO - ---------------------------------------------------------------------
[2023-02-08T20:01:06.818+0000] {spark_submit.py:495} INFO - |      default     |   13  |   13  |   13  |   0   ||   13  |   13  |
[2023-02-08T20:01:06.818+0000] {spark_submit.py:495} INFO - ---------------------------------------------------------------------
[2023-02-08T20:01:06.820+0000] {spark_submit.py:495} INFO - :: retrieving :: org.apache.spark#spark-submit-parent-d84e4a54-476c-4b5a-b5b5-9f4815458db2
[2023-02-08T20:01:06.821+0000] {spark_submit.py:495} INFO - confs: [default]
[2023-02-08T20:01:06.839+0000] {spark_submit.py:495} INFO - 13 artifacts copied, 0 already retrieved (15812kB/19ms)
[2023-02-08T20:01:07.225+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-02-08T20:01:08.242+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SparkContext: Running Spark version 3.3.1
[2023-02-08T20:01:08.262+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO ResourceUtils: ==============================================================
[2023-02-08T20:01:08.263+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-02-08T20:01:08.263+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO ResourceUtils: ==============================================================
[2023-02-08T20:01:08.264+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SparkContext: Submitted application: arrow-spark
[2023-02-08T20:01:08.300+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-02-08T20:01:08.316+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO ResourceProfile: Limiting resource is cpu
[2023-02-08T20:01:08.317+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-02-08T20:01:08.397+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SecurityManager: Changing view acls to: default
[2023-02-08T20:01:08.398+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SecurityManager: Changing modify acls to: default
[2023-02-08T20:01:08.399+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SecurityManager: Changing view acls groups to:
[2023-02-08T20:01:08.399+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SecurityManager: Changing modify acls groups to:
[2023-02-08T20:01:08.400+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(default); groups with view permissions: Set(); users  with modify permissions: Set(default); groups with modify permissions: Set()
[2023-02-08T20:01:08.771+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO Utils: Successfully started service 'sparkDriver' on port 44463.
[2023-02-08T20:01:08.812+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SparkEnv: Registering MapOutputTracker
[2023-02-08T20:01:08.845+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SparkEnv: Registering BlockManagerMaster
[2023-02-08T20:01:08.867+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-02-08T20:01:08.869+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-02-08T20:01:08.877+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-02-08T20:01:08.906+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dc92cfa5-2274-406a-a55e-8e18a321f3a9
[2023-02-08T20:01:08.927+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-02-08T20:01:08.941+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:08 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-02-08T20:01:09.118+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2023-02-08T20:01:09.148+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar at spark://b55acaa82944:44463/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.148+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at spark://b55acaa82944:44463/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.148+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar at spark://b55acaa82944:44463/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.149+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at spark://b55acaa82944:44463/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.149+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at spark://b55acaa82944:44463/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.149+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at spark://b55acaa82944:44463/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.149+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at spark://b55acaa82944:44463/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.149+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at spark://b55acaa82944:44463/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.150+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at spark://b55acaa82944:44463/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.150+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at spark://b55acaa82944:44463/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1675886468234
[2023-02-08T20:01:09.150+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at spark://b55acaa82944:44463/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.150+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar at spark://b55acaa82944:44463/jars/org.mongodb_bson-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.151+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added JAR file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at spark://b55acaa82944:44463/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.153+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar at file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.154+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar
[2023-02-08T20:01:09.164+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar at file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.164+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2023-02-08T20:01:09.167+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar at file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.167+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar
[2023-02-08T20:01:09.172+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar at file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.172+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.kafka_kafka-clients-2.6.0.jar
[2023-02-08T20:01:09.184+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar at file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.184+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.commons_commons-pool2-2.6.2.jar
[2023-02-08T20:01:09.196+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar at file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.196+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.spark-project.spark_unused-1.0.0.jar
[2023-02-08T20:01:09.199+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar at file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.200+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/com.github.luben_zstd-jni-1.4.8-1.jar
[2023-02-08T20:01:09.209+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar at file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.210+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.lz4_lz4-java-1.7.1.jar
[2023-02-08T20:01:09.214+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar at file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.214+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.xerial.snappy_snappy-java-1.1.8.2.jar
[2023-02-08T20:01:09.219+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar at file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1675886468234
[2023-02-08T20:01:09.220+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.slf4j_slf4j-api-1.7.30.jar
[2023-02-08T20:01:09.225+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar at file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.225+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2023-02-08T20:01:09.229+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar at file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.229+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_bson-4.0.5.jar
[2023-02-08T20:01:09.232+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO SparkContext: Added file file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar at file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.232+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Copying /home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-core-4.0.5.jar
[2023-02-08T20:01:09.293+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Starting executor ID driver on host b55acaa82944
[2023-02-08T20:01:09.299+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2023-02-08T20:01:09.310+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.330+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar
[2023-02-08T20:01:09.336+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.337+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2023-02-08T20:01:09.342+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.346+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.apache.kafka_kafka-clients-2.6.0.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.kafka_kafka-clients-2.6.0.jar
[2023-02-08T20:01:09.350+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.351+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.mongodb_bson-4.0.5.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_bson-4.0.5.jar
[2023-02-08T20:01:09.355+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.361+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/com.github.luben_zstd-jni-1.4.8-1.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/com.github.luben_zstd-jni-1.4.8-1.jar
[2023-02-08T20:01:09.364+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.365+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.lz4_lz4-java-1.7.1.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.lz4_lz4-java-1.7.1.jar
[2023-02-08T20:01:09.372+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.373+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.spark-project.spark_unused-1.0.0.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.spark-project.spark_unused-1.0.0.jar
[2023-02-08T20:01:09.376+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.378+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.xerial.snappy_snappy-java-1.1.8.2.jar
[2023-02-08T20:01:09.381+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.382+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.mongodb_mongodb-driver-core-4.0.5.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-core-4.0.5.jar
[2023-02-08T20:01:09.385+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.386+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar
[2023-02-08T20:01:09.389+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.390+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2023-02-08T20:01:09.394+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.394+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.apache.commons_commons-pool2-2.6.2.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.commons_commons-pool2-2.6.2.jar
[2023-02-08T20:01:09.397+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching file:///home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1675886468234
[2023-02-08T20:01:09.397+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /home/***/.ivy2/jars/org.slf4j_slf4j-api-1.7.30.jar has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.slf4j_slf4j-api-1.7.30.jar
[2023-02-08T20:01:09.402+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.apache.commons_commons-pool2-2.6.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.433+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO TransportClientFactory: Successfully created connection to b55acaa82944/172.20.0.6:44463 after 20 ms (0 ms spent in bootstraps)
[2023-02-08T20:01:09.437+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.apache.commons_commons-pool2-2.6.2.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp7057954452159783090.tmp
[2023-02-08T20:01:09.464+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp7057954452159783090.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.commons_commons-pool2-2.6.2.jar
[2023-02-08T20:01:09.467+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.commons_commons-pool2-2.6.2.jar to class loader
[2023-02-08T20:01:09.467+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.467+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp9965628494840188422.tmp
[2023-02-08T20:01:09.470+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp9965628494840188422.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar
[2023-02-08T20:01:09.473+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-sql-kafka-0-10_2.12-3.1.3.jar to class loader
[2023-02-08T20:01:09.473+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.apache.kafka_kafka-clients-2.6.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.474+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.apache.kafka_kafka-clients-2.6.0.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp14382550452823309650.tmp
[2023-02-08T20:01:09.485+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp14382550452823309650.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.kafka_kafka-clients-2.6.0.jar
[2023-02-08T20:01:09.493+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.kafka_kafka-clients-2.6.0.jar to class loader
[2023-02-08T20:01:09.493+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.493+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.mongodb_mongodb-driver-sync-4.0.5.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp6521673662453686223.tmp
[2023-02-08T20:01:09.495+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp6521673662453686223.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-sync-4.0.5.jar
[2023-02-08T20:01:09.497+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-sync-4.0.5.jar to class loader
[2023-02-08T20:01:09.497+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.slf4j_slf4j-api-1.7.30.jar with timestamp 1675886468234
[2023-02-08T20:01:09.497+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.slf4j_slf4j-api-1.7.30.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp10264019058676659238.tmp
[2023-02-08T20:01:09.499+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp10264019058676659238.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.slf4j_slf4j-api-1.7.30.jar
[2023-02-08T20:01:09.501+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.slf4j_slf4j-api-1.7.30.jar to class loader
[2023-02-08T20:01:09.502+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/com.github.luben_zstd-jni-1.4.8-1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.502+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/com.github.luben_zstd-jni-1.4.8-1.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp156636116113149985.tmp
[2023-02-08T20:01:09.520+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp156636116113149985.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/com.github.luben_zstd-jni-1.4.8-1.jar
[2023-02-08T20:01:09.608+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/com.github.luben_zstd-jni-1.4.8-1.jar to class loader
[2023-02-08T20:01:09.608+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.spark-project.spark_unused-1.0.0.jar with timestamp 1675886468234
[2023-02-08T20:01:09.609+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.spark-project.spark_unused-1.0.0.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp17814147873218418356.tmp
[2023-02-08T20:01:09.614+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp17814147873218418356.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.spark-project.spark_unused-1.0.0.jar
[2023-02-08T20:01:09.626+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.spark-project.spark_unused-1.0.0.jar to class loader
[2023-02-08T20:01:09.627+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar with timestamp 1675886468234
[2023-02-08T20:01:09.628+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp16325092698176637760.tmp
[2023-02-08T20:01:09.632+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp16325092698176637760.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar
[2023-02-08T20:01:09.642+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.1.3.jar to class loader
[2023-02-08T20:01:09.643+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.mongodb_mongodb-driver-core-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.647+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.mongodb_mongodb-driver-core-4.0.5.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp3261978061186865197.tmp
[2023-02-08T20:01:09.670+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp3261978061186865197.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-core-4.0.5.jar
[2023-02-08T20:01:09.700+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_mongodb-driver-core-4.0.5.jar to class loader
[2023-02-08T20:01:09.700+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar with timestamp 1675886468234
[2023-02-08T20:01:09.701+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.xerial.snappy_snappy-java-1.1.8.2.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp10425199074037846483.tmp
[2023-02-08T20:01:09.713+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp10425199074037846483.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.xerial.snappy_snappy-java-1.1.8.2.jar
[2023-02-08T20:01:09.721+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.xerial.snappy_snappy-java-1.1.8.2.jar to class loader
[2023-02-08T20:01:09.721+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.mongodb_bson-4.0.5.jar with timestamp 1675886468234
[2023-02-08T20:01:09.721+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.mongodb_bson-4.0.5.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp5673408177137998187.tmp
[2023-02-08T20:01:09.726+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp5673408177137998187.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_bson-4.0.5.jar
[2023-02-08T20:01:09.732+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb_bson-4.0.5.jar to class loader
[2023-02-08T20:01:09.732+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.732+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp14009629313754332253.tmp
[2023-02-08T20:01:09.740+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp14009629313754332253.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar
[2023-02-08T20:01:09.747+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.mongodb.spark_mongo-spark-connector_2.12-3.0.1.jar to class loader
[2023-02-08T20:01:09.747+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Fetching spark://b55acaa82944:44463/jars/org.lz4_lz4-java-1.7.1.jar with timestamp 1675886468234
[2023-02-08T20:01:09.748+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Fetching spark://b55acaa82944:44463/jars/org.lz4_lz4-java-1.7.1.jar to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp16860659376978781578.tmp
[2023-02-08T20:01:09.753+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/fetchFileTemp16860659376978781578.tmp has been previously copied to /tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.lz4_lz4-java-1.7.1.jar
[2023-02-08T20:01:09.763+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Executor: Adding file:/tmp/spark-70d280e0-a024-47e5-92b5-16fae57c4916/userFiles-f12a63b2-c1be-4eae-a1cd-70cdaeee36f3/org.lz4_lz4-java-1.7.1.jar to class loader
[2023-02-08T20:01:09.773+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36021.
[2023-02-08T20:01:09.773+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO NettyBlockTransferService: Server created on b55acaa82944:36021
[2023-02-08T20:01:09.775+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-02-08T20:01:09.784+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b55acaa82944, 36021, None)
[2023-02-08T20:01:09.789+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO BlockManagerMasterEndpoint: Registering block manager b55acaa82944:36021 with 434.4 MiB RAM, BlockManagerId(driver, b55acaa82944, 36021, None)
[2023-02-08T20:01:09.792+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b55acaa82944, 36021, None)
[2023-02-08T20:01:09.793+0000] {spark_submit.py:495} INFO - 23/02/08 20:01:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b55acaa82944, 36021, None)
[2023-02-08T20:01:13.896+0000] {spark_submit.py:495} INFO - 2023-02-08 20:01:13,896 - py4j.java_gateway - INFO - Callback Server Starting
[2023-02-08T20:01:13.897+0000] {spark_submit.py:495} INFO - 2023-02-08 20:01:13,897 - py4j.java_gateway - INFO - Socket listening on ('127.0.0.1', 34053)
[2023-02-08T20:01:18.979+0000] {spark_submit.py:495} INFO - 2023-02-08 20:01:18,979 - py4j.clientserver - INFO - Python Server ready to receive messages
[2023-02-08T20:01:18.980+0000] {spark_submit.py:495} INFO - 2023-02-08 20:01:18,979 - py4j.clientserver - INFO - Received command c on object id p0
[2023-02-08T20:01:19.487+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-02-08T20:01:19.488+0000] {spark_submit.py:495} INFO - Batch: 0
[2023-02-08T20:01:19.488+0000] {spark_submit.py:495} INFO - -------------------------------------------
[2023-02-08T20:01:19.578+0000] {spark_submit.py:495} INFO - +---+-------------+-----+-------------+----------+----------------+------------+-----------------+--------------+-------------+
[2023-02-08T20:01:19.578+0000] {spark_submit.py:495} INFO - |id |nameOfProduct|price|ProductStatus|SellerName|RegistrationDate|QuantitySold|QuantityAvailable|Free shipping?|Store ratings|
[2023-02-08T20:01:19.578+0000] {spark_submit.py:495} INFO - +---+-------------+-----+-------------+----------+----------------+------------+-----------------+--------------+-------------+
[2023-02-08T20:01:19.578+0000] {spark_submit.py:495} INFO - +---+-------------+-----+-------------+----------+----------------+------------+-----------------+--------------+-------------+
[2023-02-08T20:01:19.585+0000] {spark_submit.py:495} INFO - 
[2023-02-08T20:01:34.183+0000] {taskinstance.py:1327} INFO - Marking task as SUCCESS. dag_id=Streaming_pipeline_meli, task_id=consumer_data_of_topic, execution_date=20230208T200043, start_date=20230208T200045, end_date=20230208T200134
[2023-02-08T20:01:34.235+0000] {local_task_job.py:159} INFO - Task exited with return code 0
[2023-02-08T20:01:34.249+0000] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
